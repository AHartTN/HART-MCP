MCP_TOKEN=CopilotOftenDoesStupidThings

SQL_SERVER_DRIVER={ODBC Driver 18 for SQL Server}
# For Dockerized mcp-server to connect to a host-based SQL Server, use 'host.docker.internal'.
# Otherwise, use the IP address or hostname of your SQL Server instance.
SQL_SERVER_SERVER=localhost
SQL_SERVER_DATABASE=HART-MCP
SQL_SERVER_USERNAME=HART-MCP
SQL_SERVER_UID=HART-MCP
SQL_SERVER_PASSWORD=...
SQL_SERVER_PWD=...

# For Dockerized Milvus, use the service name defined in docker-compose (e.g., 'milvus').
# Otherwise, use the IP address or hostname of your Milvus instance.
MILVUS_HOST=192.168.1.2
MILVUS_PORT=19530
MILVUS_USER=milvus
MILVUS_UID=milvus
MILVUS_PASSWORD=...
MILVUS_PWD=...
MILVUS_COLLECTION=rag_collection

# For Dockerized Neo4j, use the service name defined in docker-compose (e.g., 'bolt://neo4j:7687').
# Otherwise, use the URI of your Neo4j instance.
NEO4J_URI=bolt://192.168.1.2:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=...

AZURE_KEYVAULT_URL=https://....vault.azure.net/
AZURE_TENANT_ID=...
AZURE_CLIENT_ID=...
AZURE_CLIENT_SECRET=...
AZURE_SUBSCRIPTION_ID=...
AZURE_RESOURCE_GROUP=...

# --- LLM Configuration ---
LLM_SOURCE=gemini # Options: gemini, claude, llama, ollama

# Gemini Specific
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL_NAME=gemini-pro # Optional: Default model name
GEMINI_TEMPERATURE=0.7 # Optional: Default temperature
GEMINI_MAX_TOKENS=2048 # Optional: Default max tokens

# Claude Specific
ANTHROPIC_API_KEY=your_anthropic_api_key_here
CLAUDE_MODEL_NAME=claude-3-opus-20240229 # Optional: Default model name
CLAUDE_TEMPERATURE=0.7 # Optional: Default temperature
CLAUDE_MAX_TOKENS=2048 # Optional: Default max tokens

# Llama (Hugging Face Inference API) Specific
HUGGINGFACE_API_TOKEN=your_huggingface_api_token_here
LLAMA_MODEL_NAME=meta-llama/Llama-2-7b-chat-hf # Optional: Example model name
LLAMA_TEMPERATURE=0.7 # Optional: Default temperature
LLAMA_MAX_TOKENS=2048 # Optional: Default max tokens

# Ollama Specific
OLLAMA_BASE_URL=http://localhost:11434 # Optional: Default Ollama base URL
OLLAMA_MODEL_NAME=llama2 # Optional: Default Ollama model name
OLLAMA_TEMPERATURE=0.7 # Optional: Default temperature
OLLAMA_MAX_TOKENS=2048 # Optional: Default max tokens